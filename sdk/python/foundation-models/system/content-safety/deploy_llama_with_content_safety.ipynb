{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to create an Azure AI Content safety enabled LLaMA online endpoint\n",
    "### This notebook will walk you through the steps to create an __Azure AI Content Safety__ enabled __LLaMA__ online endpoint.\n",
    "### The steps are:\n",
    "1. Create an __Azure AI Content Safety__ resource for moderating the request from user and response from the __LLaMA__ online endpoint.\n",
    "2. Create a new __Azure AI Content Safety__ enabled __LLaMA__ online endpoint with a custom score.py which will integrate with the __Azure AI Content Safety__ resource to moderate the response from the __LLaMA__ model and the request from the user, but to make the custom score.py to sucessfully autheticated to the __Azure AI Content Safety__ resource, we have 2 options:\n",
    "    1. __UAI__, recommended but more complex approach, is to create a __User Assigned Identity (UAI)__ and assign appropriate roles to the __UAI__. Then, the custom score.py can obtain the access token of the __UAI__ from the AAD server to access the Azure AI Content Safety resource.\n",
    "    2. __Environment variable__, simpler but less secure approach, is to just pass the access key of the __Azure AI Content Safety__ resource to the custom score.py via environment variable, then the custom score.py can use the key directly to access the Azure AI Content Safety resource, this option is less secure than the first option, if someone in your org has access to the endpoint, he/she can get the access key from the environment variable and use it to access the Azure AI Content Safety resource.\n",
    "  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Prerequisites\n",
    "#### 1.1 Check List:\n",
    "- [x] You have created an new Python virtual environment for this notebook.\n",
    "- [x] The identity you are using to execute this notebook(yourself or your VM) need to have the __Contributor__ role on the resource group where the AML Workspace your specified is located, because this notebook will create an Azure AI Content Safety resource using that identity.\n",
    "- [x] Required If you choose to use the UAI approach, the identity executing this notebook (either yourself or your virtual machine) needs to have the owner role on the resource group that contains the specified AML Workspace. This is because the notebook will create a new UAI and assign the UAI some required roles to successfully create the Azure AI Content Safety enabled LLaMA endpoint."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment the following lines to install the required packages\n",
    "%pip install azure-identity==1.13.0\n",
    "%pip install azure-mgmt-cognitiveservices==13.4.0\n",
    "%pip install azure-ai-ml==1.8.0\n",
    "%pip install azure-mgmt-msi==7.0.0\n",
    "%pip install azure-mgmt-authorization==3.0.0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Assign variables for the workspace and deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Update following workspace information to contain\n",
    "#       your subscription ID, resource group name, and workspace name\n",
    "subscription_id = \"\"\n",
    "resource_group = \"\"\n",
    "workspace_name = \"\"\n",
    "\n",
    "# The public registry name contains LLaMA models\n",
    "registry_name=\"azureml-preview-test1\"\n",
    "\n",
    "# Name of the LLaMA model to be deployed\n",
    "# available_llama_models_pre_trained = [\"Llama-2-7b\", \"Llama-2-13b\"]\n",
    "# available_llama_models_fine_tuned = [\"Llama-2-7b-chat\", \"Llama-2-13b-chat\"]\n",
    "model_name=\"Llama-2-7b\"\n",
    "\n",
    "endpoint_name=\"llama-large\" # Replace with your endpoint name\n",
    "deployment_name=\"llama\" # Replace with your deployment name\n",
    "sku_name=\"Standard_NC24s_v3\" # Name of the sku(instance type) Check the model-list(can be found in the parent folder(inference)) to get the most optimal sku for your model (Default: Standard_DS2_v2)\n",
    "\n",
    "\n",
    "# settings for the Azure AI Content Safety resource\n",
    "aacs_name = f\"{endpoint_name}-aacs-1\" # name of azure ai content safety resource, has to be unique\n",
    "available_aacs_locations = ['east us', 'west europe']\n",
    "aacs_location = available_aacs_locations[0]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Connect to your AML Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
    "\n",
    "try:\n",
    "    credential = DefaultAzureCredential()\n",
    "    # Check if given credential can get token successfully.\n",
    "    credential.get_token(\"https://management.azure.com/.default\")\n",
    "except Exception as ex:\n",
    "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
    "    credential = InteractiveBrowserCredential()\n",
    "\n",
    "try:\n",
    "    ml_client = MLClient.from_config(credential=credential)\n",
    "except Exception as ex:\n",
    "    ml_client = MLClient(credentials=credential, subscription_id=subscription_id, resource_group=resource_group, workspace_name=workspace_name)\n",
    "\n",
    "\n",
    "\n",
    "workspace_location = ml_client.workspaces.get(ml_client.workspace_name).location\n",
    "workspace_resource_id = ml_client.workspaces.get(ml_client.workspace_name).id\n",
    "subscription_id = ml_client.subscription_id\n",
    "resource_group_name = ml_client.resource_group_name\n",
    "workspace_name = ml_client.workspace_name\n",
    "\n",
    "reg_client = MLClient(credential, subscription_id=subscription_id, resource_group_name=resource_group_name, registry_name=registry_name)\n",
    "print(f\"Connected to workspace {workspace_resource_id}\")\n",
    "print(f\"Workspace location is {workspace_location}\") "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Create Azure AI Content Safety"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Choose a region for your Azure AI Content Safety\n",
    "Currently, Azure AI Content Safety only available in the following regions:\n",
    "- East US\n",
    "- West Europe\n",
    "\n",
    "__NOTE__: before you choose the region to deploy the Azure AI Content Safety, please aware of that your data will be transferred to the region you choose and by selecting a region outside your current location, you may be allowing the transmission of your data to regions outside your jurisdiction. It is important to note that data protection and privacy laws may vary between jurisdictions. Before proceeding, we strongly advise you to familiarize yourself with the local laws and regulations governing data transfer and ensure that you are legally permitted to transmit your data to an overseas location for processing. By continuing with the selection of a different region, you acknowledge that you have understood and accepted any potential risks associated with such data transmission. Please proceed with caution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.mgmt.cognitiveservices import CognitiveServicesManagementClient\n",
    "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
    "from azure.mgmt.cognitiveservices.models import Account, Sku, AccountProperties\n",
    "import time\n",
    "\n",
    "try:\n",
    "    credential = DefaultAzureCredential()\n",
    "    # Check if given credential can get token successfully.\n",
    "    credential.get_token(\"https://management.azure.com/.default\")\n",
    "except Exception as ex:\n",
    "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
    "    credential = InteractiveBrowserCredential()\n",
    "\n",
    "client = CognitiveServicesManagementClient(credential, subscription_id)\n",
    "\n",
    "# create a new Cognitive Services Account\n",
    "kind = \"ContentSafety\"\n",
    "aacs_sku_name = \"S0\"\n",
    "parameters = Account(sku=Sku(name=aacs_sku_name), kind=kind, location=aacs_location, properties= AccountProperties(custom_sub_domain_name=aacs_name, public_network_access=\"Enabled\"))\n",
    "# How many seconds to wait between checking the status of an async operation.\n",
    "wait_time = 10\n",
    "\n",
    "\n",
    "try:\n",
    "    client.accounts.get(resource_group_name, aacs_name)\n",
    "    print(f\"Found existing Azure AI content safety Account {aacs_name}.\")\n",
    "except:\n",
    "    print(f\"Creating Azure AI content safety Account {aacs_name}.\")\n",
    "    poller = client.accounts.begin_create(resource_group_name, aacs_name, parameters)\n",
    "    while (not poller.done()) :\n",
    "        print(\"Waiting {wait_time} seconds for operation to finish.\".format(wait_time=wait_time))\n",
    "        time.sleep (wait_time)\n",
    "        # This will raise an exception if the server responded with an error.\n",
    "        result = poller.result()\n",
    "    print(\"Resource created.\")\n",
    "\n",
    "\n",
    "\n",
    "aacs=client.accounts.get(resource_group_name, aacs_name)\n",
    "aacs_endpoint = aacs.properties.endpoint\n",
    "aacs_resource_id = aacs.id\n",
    "print(f\"AACS endpoint is {aacs_endpoint}\")\n",
    "print(f\"AACS ResourceId is {aacs_resource_id}\")\n",
    "\n",
    "aacs_access_key = client.accounts.list_keys(resource_group_name=resource_group_name, account_name=aacs_name).key1\n",
    "print(f\"AACS access key is {aacs_access_key}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Create LLaMA online endpoint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 Decide on SKU and instance count for the LLaMA online endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Will create LLaMA endpoint {endpoint_name} using {sku_name} compute instance(s)\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Check if LLaMA model is available in the AML registry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "version_list = list(reg_client.models.list(model_name)) # list available versions of the model\n",
    "llama_model = None\n",
    "if len(version_list) == 0:\n",
    "    print(\"Model not found in registry\")\n",
    "else:\n",
    "    model_version = version_list[0].version\n",
    "    llama_model = reg_client.models.get(model_name, model_version)\n",
    "    print(\n",
    "        f\"Using model name: {llama_model.name}, version: {llama_model.version}, id: {llama_model.id} for inferencing\"\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3 Create LLaMA online endpoint\n",
    "This step may take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import ManagedOnlineEndpoint\n",
    "# Check if the endpoint already exists in the workspace\n",
    "try:\n",
    "    endpoint = ml_client.online_endpoints.get(endpoint_name)\n",
    "    print(\"---Endpoint already exists---\")\n",
    "except:\n",
    "    # Create an online endpoint if it doesn't exist\n",
    "\n",
    "    # Define the endpoint\n",
    "    endpoint = ManagedOnlineEndpoint(name=endpoint_name, description=\"Test endpoint for model\")\n",
    "\n",
    "    # Trigger the endpoint creation\n",
    "    try:\n",
    "        ml_client.begin_create_or_update(endpoint).wait()\n",
    "        print(\"\\n---Endpoint created successfully---\\n\")\n",
    "    except Exception as err:\n",
    "        raise RuntimeError(f\"Endpoint creation failed. Detailed Response:\\n{err}\") from err"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Create the Azure AI Content Safety enabled LLaMA online endpoint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.1 Create environment for LLaMA endpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import (\n",
    "    Environment,\n",
    "    BuildContext\n",
    ")\n",
    "try:\n",
    "    env = ml_client.environments.get(\"LLaMA-ENVIRONMENT\", label=\"latest\")\n",
    "    print(\"---Environment already exists---\")\n",
    "except:\n",
    "    print(\"---Creating environment---\")\n",
    "    env = Environment(name = \"LLaMA-ENVIRONMENT\", build= BuildContext(path='./docker_env') )\n",
    "    ml_client.environments.create_or_update(env)\n",
    "\n",
    "\n",
    "# TODO: Add a check to see if the job finished\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7.3.2 Create the Safety-Enabled LLaMA Online Endpoint\n",
    "This step may take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import (\n",
    "    CodeConfiguration,\n",
    "    OnlineRequestSettings,\n",
    "    ManagedOnlineDeployment\n",
    ")\n",
    "\n",
    "# Define the deployment\n",
    "# Update the model version as necessary\n",
    "deployment = ManagedOnlineDeployment(\n",
    "    name=deployment_name,\n",
    "    endpoint_name=endpoint_name,\n",
    "    model=llama_model.id,\n",
    "    instance_type=sku_name,\n",
    "    instance_count=1,\n",
    "    code_configuration=CodeConfiguration(\n",
    "        code=\"./score\", scoring_script=\"score.py\"\n",
    "    ),\n",
    "    environment = env,\n",
    "    environment_variables= {\n",
    "        \"MLFLOW_MODEL_FOLDER\":\"mlflow_model_folder\",\n",
    "        \"CONTENT_SAFETY_ENDPOINT\": aacs_endpoint,\n",
    "        \"CONTENT_SAFETY_KEY\": aacs_access_key\n",
    "    },\n",
    "    request_settings= OnlineRequestSettings(request_timeout_ms=90000)\n",
    ")\n",
    "\n",
    "# Trigger the deployment creation\n",
    "try:\n",
    "    ml_client.begin_create_or_update(deployment).wait()\n",
    "    print(\"\\n---Deployment created successfully---\\n\")\n",
    "except Exception as err:\n",
    "    raise RuntimeError(f\"Deployment creation failed. Detailed Response:\\n{err}\") from err\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Test the Safety Enabled LLaMA online endpoint."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.1 Test endpoint with normal sample request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "test_src_dir = \"./safety-llama-test\"\n",
    "os.makedirs(test_src_dir, exist_ok=True)\n",
    "print(f\"test script directory: {test_src_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile {test_src_dir}/sample-request.json\n",
    "{\n",
    "    \"input_data\": {\n",
    "          \"columns\": [\"input_string\"],\n",
    "          \"index\": [0],\n",
    "          \"data\": [ \"My name is John and I \" ]\n",
    "        }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = f\"{test_src_dir}/sample-request.json\"\n",
    "ml_client.online_endpoints.invoke(\n",
    "        endpoint_name=endpoint_name, \n",
    "        deployment_name=deployment_name,\n",
    "        request_file=sample_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.2 Test endpoint with harmful sample request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile {test_src_dir}/sample-harmful-request.json\n",
    "{\n",
    "    \"input_data\": {\n",
    "          \"columns\": [\"input_string\"],\n",
    "          \"index\": [0],\n",
    "          \"data\": [ \"I wanna kill you\" ]\n",
    "        }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = f\"{test_src_dir}/sample-harmful-request.json\"\n",
    "ml_client.online_endpoints.invoke(\n",
    "        endpoint_name=endpoint_name, \n",
    "        deployment_name=deployment_name,\n",
    "        request_file=sample_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
